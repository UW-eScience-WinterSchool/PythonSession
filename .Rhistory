#library(factoextra)
res.agnes= hcut(dataToCluster_DM,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "ward.D2")
# Hierarchical technique- divisive approach
res.diana= hcut(dataToCluster_DM,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='diana',
hc_method = "ward.D2")
fromPy$pam=as.factor(res.pam$clustering)
fromPy$agn=as.factor(res.agnes$cluster)
fromPy$dia=as.factor(res.diana$cluster)
aggregate(data=fromPy,
Overallscore~pam,
FUN=mean)
aggregate(data=fromPy,
Overallscore~agn,
FUN=mean)
aggregate(data=fromPy,
Overallscore~dia,
FUN=mean)
library(dplyr)
fromPy$pam=dplyr::recode_factor(fromPy$pam,
`1` = '4',`2`='3',`3`='2',`4`='1')
fromPy$agn=dplyr::recode_factor(fromPy$agn,
`1` = '4',`2`='3',`3`='2',`4`='1')
fromPy$dia=dplyr::recode_factor(fromPy$dia,
`1` = '4',`2`='3',`3`='2',`4`='1')
# from factoextra
fviz_silhouette(res.pam)
fviz_silhouette(res.agnes)
library(factoextra)
fviz_silhouette(res.diana)
head(data.frame(res.pam$silinfo$widths),10)
pamEval=data.frame(res.pam$silinfo$widths)
agnEval=data.frame(res.agnes$silinfo$widths)
diaEval=data.frame(res.diana$silinfo$widths)
pamPoor=rownames(pamEval[pamEval$sil_width<0,])
agnPoor=rownames(agnEval[agnEval$sil_width<0,])
diaPoor=rownames(diaEval[diaEval$sil_width<0,])
library("qpcR")
bap_Clus=as.data.frame(qpcR:::cbind.na(sort(pamPoor), sort(agnPoor),sort(diaPoor)))
bap_Clus
projectedData = cmdscale(dataToCluster_DM, k=2)
#
# save coordinates to original data frame:
fromPy$dim1 = projectedData[,1]
fromPy$dim2 = projectedData[,2]
# see:
fromPy[,c('dim1','dim2')]
base= ggplot(data=fromPy,
aes(x=dim1, y=dim2,
label=Country))
base + geom_text(size=2)
pamPlot=base + labs(title = "PAM") + geom_point(size=2,
aes(color=pam),
show.legend = T)
pamPlot
agnPlot=base + labs(title = "AGNES") + geom_point(size=2,
aes(color=agn),
show.legend = T)
agnPlot=base + labs(title = "AGNES") + geom_point(size=2,
aes(color=agn),
show.legend = T)
diaPlot=base + labs(title = "DIANA") + geom_point(size=2,
aes(color=dia),
show.legend = T)
library(ggpubr)
ggarrange(pamPlot, agnPlot, diaPlot,ncol = 3,common.legend = T)
# If name of country in black list, use it, else get rid of it
LABELpam=ifelse(fromPy$Country%in%pamPoor,fromPy$Country,"")
LABELdia=ifelse(fromPy$Country%in%diaPoor,fromPy$Country,"")
LABELagn=ifelse(fromPy$Country%in%agnPoor,fromPy$Country,"")
library(ggrepel)
pamPlot + geom_text_repel(aes(label=LABELpam))
diaPlot + geom_text_repel(aes(label=LABELdia))
agnPlot + geom_text_repel(aes(label=LABELagn))
fviz_dend(res.agnes,k=NumberOfClusterDesired, cex = 0.45, horiz = T,main = "AGNES approach")
fviz_dend(res.diana,k=NumberOfClusterDesired, cex = 0.45, horiz = T,main = "DIANA approach")
selection=c("Country","Electoralprocessandpluralism", "Functioningofgovernment","Politicalparticipation","Politicalculture", "Civilliberties")
dataForFA=fromPy[,selection]
selection=c("Country","Electoralprocessandpluralism", "Functioningofgovernment","Politicalparticipation","Politicalculture", "Civilliberties")
dataForFA=fromPy[,selection]
names(dataForFA)
library(lavaan)
model='
democra=~Electoralprocessandpluralism + Functioningofgovernment + Politicalparticipation + Politicalculture + Civilliberties
'
fit<-cfa(model, data = dataForFA,std.lv=TRUE)
indexCFA=lavPredict(fit)
indexCFA[1:10]
library(scales)
indexCFANorm=rescale(as.vector(indexCFA),
to = c(0, 10))
indexCFANorm[1:10]
fromPy$demo_FA=indexCFANorm
base=ggplot(data=fromPy,
aes(x=demo_FA,y=Overallscore))
base+geom_point()
evalCFA1=parameterEstimates(fit, standardized =TRUE)
evalCFA1[evalCFA1$op=="=~",c('rhs','std.all','pvalue')]
evalCFA2=as.list(fitMeasures(fit))
evalCFA2[c("chisq", "df", "pvalue")]
evalCFA2$tli # > 0.90
evalCFA2[c( 'rmsea.ci.lower','rmsea','rmsea.ci.upper')]
library(semPlot)
semPaths(fit, what='std', nCharNodes=0, sizeMan=12,
edge.label.cex=1.5, fade=T,residuals = F)
fromPy[,c('dim1','dim2')][,c(1:10)]
fromPy[,c('dim1','dim2')][c(1:10)]
fromPy
fromPy[,c('dim1','dim2')]
fromPy[,c('dim1','dim2')][1]
fromPy[,c('dim1','dim2')][1,]
fromPy[,c('dim1','dim2')][1:10,]
link='https://github.com/EvansUW-GovAnalytics-Project/students_merge/raw/main/demohdikw.RDS'
# a RDS file from the web needs:
myFile=url(link)
# reading in data:
fromPy=readRDS(file = myFile)
# reset indexes to R format:
row.names(fromPy)=NULL
link='https://github.com/EvansUW-GovAnalytics-Project/students_merge/raw/main/demohdikw.RDS'
# a RDS file from the web needs:
myFile=url(link)
# reading in data:
fromPy=readRDS(file = myFile)
# reset indexes to R format:
row.names(fromPy)=NULL
str(fromPy,width = 70,strict.width='cut')
# hypothesis 1: HDI increases as Democracy advances:
hypo1=formula(HDI~ Score)
# hypothesis 2: HDI increases as Democracy and Industrialization advance:
hypo2=formula(HDI~ Score + kWh_pop)
#
# results
gauss1=glm(hypo1,
data = fromPy,
family = 'gaussian')
View(fromPy)
link='https://github.com/EvansDataScience/CTforGA_integrating/raw/main/allDataFull_OK.RDS'
# a RDS file from the web needs:
myFile=url(link)
# reading in data:
fromPy=readRDS(file = myFile)
# reset indexes to R format:
row.names(fromPy)=NULL
View(fromPy)
str(fromPy,width = 70,strict.width='cut')
names(fromPy)
link='https://github.com/EvansDataScience/CTforGA_integrating/raw/main/allDataFull_OK.RDS'
# a RDS file from the web needs:
myFile=url(link)
# reading in data:
fromPy=readRDS(file = myFile)
# reset indexes to R format:
row.names(fromPy)=NULL
idhLink="https://github.com/EvansDataScience/CTforGA_BasicModeling/raw/main/hdi2019.csv"
idhdata=read.csv(idhLink)
View(fromPy)
View(idhdata)
merge(fromPy,idhdata,by.x = "Country",by.y = "country")
demoidh=merge(fromPy,idhdata,by.x = "Country",by.y = "country")
str(demoidh,width = 70,strict.width='cut')
# hypothesis 1: hdi increases as we have more civil liberties:
hypo1=formula(hdi~ Civilliberties)
# hypothesis 2: hdi increases as Civil liberties and Political participation advance:
hypo2=formula(hdi~ Civilliberties + Politicalparticipation)
#
# results
gauss1=glm(hypo1,
data = fromPy,
family = 'gaussian')
#
# results
gauss1=glm(hypo1,
data = demoidh,
family = 'gaussian')
gauss2=glm(hypo2,
data = fromPy,
family = 'gaussian')
#
# results
gauss1=glm(hypo1,
data = demoidh,
family = 'gaussian')
gauss2=glm(hypo2,
data = demoidh,
family = 'gaussian')
summary(gauss1)
summary(gauss2)
anova(gauss1,gauss2,test="Chisq")
library(rsq)
rsq(gauss2,adj=T)
plot(gauss2,1)
plot(gauss2,2)
# The data is normal if the p-value is above 0.05
shapiro.test(gauss2$residuals)
plot(gauss2, 3)
library(lmtest)
#pvalue<0.05 you cannot assume Homoscedasticity
bptest(gauss2)
library(car)
vif(gauss2) # lower than 5 is desirable
plot(gauss2,5)
gaussInf=as.data.frame(influence.measures(gauss2)$is.inf)
gaussInf[gaussInf$cook.d,]
library(sjPlot)
plot_models(gauss2,vline.color = "grey")
library(caret)
set.seed(123)
selection = createDataPartition(fromPy$HDI,
p = 0.75,
list = FALSE)
library(caret)
set.seed(123)
selection = createDataPartition(demoidh$hdi,
p = 0.75,
list = FALSE)
#
trainGauss = fromPy[ selection, ]
#
testGauss  = fromPy[-selection, ]
ctrl = trainControl(method = 'cv',number = 5)
gauss2CV = train(hypo2,
data = trainGauss,
method = 'glm',
trControl = ctrl)
library(caret)
set.seed(123)
selection = createDataPartition(demoidh$hdi,
p = 0.75,
list = FALSE)
#
trainGauss = demoidh[ selection, ]
#
testGauss  = demoidh[-selection, ]
ctrl = trainControl(method = 'cv',number = 5)
gauss2CV = train(hypo2,
data = trainGauss,
method = 'glm',
trControl = ctrl)
summary(gauss2CV)
predictedVal<-predict(gauss2CV,testGauss)
postResample(obs = testGauss$HDI,
pred=predictedVal)
ctrl = trainControl(method = 'cv',number = 5)
gauss2CV = train(hypo2,
data = trainGauss,
method = 'glm',
trControl = ctrl)
summary(gauss2CV)
predictedVal<-predict(gauss2CV,testGauss)
postResample(obs = testGauss$hdi,
pred=predictedVal)
?postResample
ctrl = trainControl(method = 'cv',number = 5)
gauss2CV = train(hypo2,
data = trainGauss,
method = 'glm',
trControl = ctrl)
gauss2CV
postResample$HDIdico=ifelse(demoidh$hdi>median(demoidh$hdi,
na.rm = T),
1,0)
demoidh$hdi
median(demoidh$hdi,
na.rm = T)
demoidh$HDIdico=ifelse(demoidh$hdi>median(demoidh$hdi,
na.rm = T),
1,0)
hypoDico1=formula(hdi~ Civilliberties)
hypoDico2=formula(hdi~ Civilliberties + Politicalparticipation)
demoidh$HDIdico=factor(demoidh$HDIdico)
hypoDico1=formula(HDIdico~ Civilliberties)
hypoDico2=formula(HDIdico~ Civilliberties + Politicalparticipation)
demoidh$HDIdico=factor(demoidh$HDIdico)
Logi1=glm(hypoDico1,data = demoidh,
family = "binomial")
Logi2=glm(hypoDico2,data = demoidh,
family = "binomial")
summary(Logi1)
summary(Logi2)
lrtest(Logi1,Logi2)
DataRegLogis=fromPy
DataRegLogis$demoTEST=fromPy$Score*log(fromPy$Score)
DataRegLogis=demoidh
DataRegLogis$civilTEST=demoidh$Civilliberties*log(demoidh$Civilliberties)
DataRegLogis$particTEST=demoidh$Politicalparticipation*log(demoidh$Politicalparticipation)
DicoTest=formula(HDIdico~ Civilliberties + Politicalparticipation + civilTEST + particTEST)
summary(glm(DicoTest,data=DataRegLogis,family = binomial))
car::box.tidwell(DicoTest,data=DataRegLogis)
car::boxTidwell(DicoTest,data=DataRegLogis)
car::boxTidwell(hypoDico2,data=DataRegLogis)
car::boxTidwell(hypoDico2,data=idhdata)
car::boxTidwell(hypoDico2,data=demoidh)
demoidh
car::boxTidwell(hypoDico2,data=demoidh)
hypoDico2
car::boxTidwell(hypoDico2,data=demoidh)
View(demoidh)
vif(Logi2)
plot(Logi2,5)
library(margins)
(modelChosen = margins(Logi2))
(margins=summary(modelChosen))
base= ggplot(margins,aes(x=factor, y=AME)) + geom_point()
plot2 = base + theme(axis.text.x = element_text(angle = 80,
size = 6,
hjust = 1))
plot2
plot2 +  geom_errorbar(aes(ymin=lower, ymax=upper))
DataRegLogis
set.seed(123)
selection = createDataPartition(demoidh$HDIdico,
p = 0.75,
list = FALSE)
trainLogi = demoidh[selection, ]
testLogi  = demoidh[-selection, ]
set.seed(123)
ctrl = trainControl(method = 'cv',number = 5)
Logis2CV = train(hypoDico2,
data = trainLogi,
method = 'glm',
family="binomial",
trControl = ctrl)
Logis2CV
predictions = predict(Logis2CV,
newdata=testLogi,
type='raw')
confusionMatrix(data=predictions,
reference=testLogi$HDIdico,
positive = "1")
link='https://github.com/EvansDataScience/CTforGA_integrating/raw/main/allDataFull_OK.RDS'
# a RDS file from the web needs:
myFile=url(link)
# reading in data:
fromPy=readRDS(file = myFile)
# reset indexes to R format:
row.names(fromPy)=NULL
# check data types
str(fromPy)
link='https://github.com/EvansDataScience/CTforGA_integrating/raw/main/allDataFull_OK.csv'
# a RDS file from the web needs:
myFile=url(link)
# reading in data:
fromPy=read.csv(link)
# reset indexes to R format:
row.names(fromPy)=NULL
# check data types
str(fromPy)
View(fromPy)
selection=c("Country","Electoralprocessandpluralism", "Functioningofgovernment","Politicalparticipation","Politicalculture", "Civilliberties")
dataToCluster=fromPy[,selection]
View(fromPy)
View(dataToCluster)
row.names(dataToCluster)=dataToCluster$Country
dataToCluster$Country=NULL
boxplot(dataToCluster,horizontal = T, las=2,cex.axis=0.4)
as.data.frame(scale(dataToCluster))
set.seed(999) # this is for replicability of results
library(cluster)
dataToCluster_DM=daisy(x=dataToCluster, metric = "gower")
dataToCluster_DM
library(factoextra)
fviz_nbclust(dataToCluster,
pam,
diss=dataToCluster_DM,
method = "gap_stat",
k.max = 10,verbose = F)
fviz_nbclust(dataToCluster,
hcut,
diss=dataToCluster_DM,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "agnes")
fviz_nbclust(dataToCluster,
hcut,
diss=dataToCluster_DM,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "diana")
NumberOfClusterDesired=4
# Partitioning technique
res.pam = pam(x=dataToCluster_DM,
k = NumberOfClusterDesired,
cluster.only = F)
# Hierarchical technique- agglomerative approach
#library(factoextra)
res.agnes= hcut(dataToCluster_DM,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "ward.D2")
# Hierarchical technique- divisive approach
res.diana= hcut(dataToCluster_DM,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='diana',
hc_method = "ward.D2")
fromPy$pam=as.factor(res.pam$clustering)
fromPy$agn=as.factor(res.agnes$cluster)
fromPy$dia=as.factor(res.diana$cluster)
aggregate(data=fromPy,
Overallscore~pam,
FUN=mean)
aggregate(data=fromPy,
Overallscore~agn,
FUN=mean)
aggregate(data=fromPy,
Overallscore~dia,
FUN=mean)
library(dplyr)
fromPy$pam=dplyr::recode_factor(fromPy$pam,
`1` = '4',`2`='3',`3`='2',`4`='1')
fromPy$agn=dplyr::recode_factor(fromPy$agn,
`1` = '4',`2`='3',`3`='2',`4`='1')
fromPy$dia=dplyr::recode_factor(fromPy$dia,
`1` = '4',`2`='3',`3`='2',`4`='1')
# from factoextra
fviz_silhouette(res.pam)
fviz_silhouette(res.agnes)
library(factoextra)
fviz_silhouette(res.diana)
head(data.frame(res.pam$silinfo$widths),10)
pamEval=data.frame(res.pam$silinfo$widths)
agnEval=data.frame(res.agnes$silinfo$widths)
diaEval=data.frame(res.diana$silinfo$widths)
pamPoor=rownames(pamEval[pamEval$sil_width<0,])
agnPoor=rownames(agnEval[agnEval$sil_width<0,])
diaPoor=rownames(diaEval[diaEval$sil_width<0,])
library("qpcR")
bap_Clus=as.data.frame(qpcR:::cbind.na(sort(pamPoor), sort(agnPoor),sort(diaPoor)))
bap_Clus
library("qpcR")
bap_Clus=as.data.frame(qpcR:::cbind.na(sort(pamPoor), sort(agnPoor),sort(diaPoor)))
names(bap_Clus)=c("pam","agn","dia")
bap_Clus
projectedData = cmdscale(dataToCluster_DM, k=2)
#
# save coordinates to original data frame:
fromPy$dim1 = projectedData[,1]
fromPy$dim2 = projectedData[,2]
# see some:
fromPy[,c('dim1','dim2')][1:10,]
base= ggplot(data=fromPy,
aes(x=dim1, y=dim2,
label=Country))
base + geom_text(size=2)
pamPlot=base + labs(title = "PAM") + geom_point(size=2,
aes(color=pam),
show.legend = T)
agnPlot=base + labs(title = "AGNES") + geom_point(size=2,
aes(color=agn),
show.legend = T)
diaPlot=base + labs(title = "DIANA") + geom_point(size=2,
aes(color=dia),
show.legend = T)
library(ggpubr)
ggarrange(pamPlot, agnPlot, diaPlot,ncol = 3,common.legend = T)
# If name of country in black list, use it, else get rid of it
LABELpam=ifelse(fromPy$Country%in%pamPoor,fromPy$Country,"")
LABELdia=ifelse(fromPy$Country%in%diaPoor,fromPy$Country,"")
LABELagn=ifelse(fromPy$Country%in%agnPoor,fromPy$Country,"")
library(ggrepel)
pamPlot + geom_text_repel(aes(label=LABELpam))
diaPlot + geom_text_repel(aes(label=LABELdia))
agnPlot + geom_text_repel(aes(label=LABELagn))
fviz_dend(res.agnes,k=NumberOfClusterDesired, cex = 0.45, horiz = T,main = "AGNES approach")
selection=c("Country","Electoralprocessandpluralism", "Functioningofgovernment","Politicalparticipation","Politicalculture", "Civilliberties")
dataForFA=fromPy[,selection]
names(dataForFA)
library(lavaan)
model='
democra=~Electoralprocessandpluralism + Functioningofgovernment + Politicalparticipation + Politicalculture + Civilliberties
'
fit<-cfa(model, data = dataForFA,std.lv=TRUE)
indexCFA=lavPredict(fit)
indexCFA[1:10]
library(scales)
indexCFANorm=rescale(as.vector(indexCFA),
to = c(0, 10))
indexCFANorm[1:10]
indexCFANorm
fromPy$demo_FA=indexCFANorm
base=ggplot(data=fromPy,
aes(x=demo_FA,y=Overallscore))
base+geom_point()
evalCFA1=parameterEstimates(fit, standardized =TRUE)
evalCFA1[evalCFA1$op=="=~",c('rhs','std.all','pvalue')]
evalCFA2=as.list(fitMeasures(fit))
evalCFA2[c("chisq", "df", "pvalue")]
evalCFA2$tli # > 0.90
evalCFA2[c( 'rmsea.ci.lower','rmsea','rmsea.ci.upper')]
library(semPlot)
semPaths(fit, what='std', nCharNodes=0, sizeMan=12,
edge.label.cex=1.5, fade=T,residuals = F)
setwd("~/Documents/eScience_UW/WiinterSchool/PythonSession")
load("allmerged.rds")
load(file="allmerged.rds")
datacc=readRDS(file = "allmerged.rds")
View(datacc)
str(datacc)
mapa=sf::read_sf("countriesMap.shp")
str(mapa)
datacc=readRDS(file = "allmerged.rds")
str(datacc)
